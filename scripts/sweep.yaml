program: train.py 
command: 
- python 
- ${program}
- --output_dir 
- ./Distillation_sweeps
- --vocab_path 
- vocab_bzd.json
- --do_train 
- True 
- --do_eval 
- True 
- --src_lang 
- esp
- --tgt_lang 
- bzd  
- --train_file 
- train_distillation_esp_bzd.json  
- --validation_file 
- val_distillation_esp_bzd.json  
- --per_device_eval_batch_size 
- 128
- --per_device_train_batch_size 
- 128
- --evaluation_strategy 
- steps 
- --eval_steps 
- 500
- --logging_strategy 
- steps 
- --logging_steps 
- 500 
- --load_best_model_at_end 
- True 
- --metric_for_best_model 
- bleu 
- --save_strategy 
- steps 
- --save_steps 
- 1000 
- --save_total_limit 
- 2 
- --num_train_epochs 
- 35
- --overwrite_output_dir
- True  
- --do_predict
- True 
- --predict_with_generate
- True  
- --test_file 
- val_distillation_esp_bzd.json
- --eval_accumulation_steps
- 4
- ${args}
method: grid
metric:
  goal: maximize
  name: eval/bleu
parameters:
  gradient_accumulation: 
    values: [2, 4]
  learning_rate:
    values: [5e-4, 5e-5, 5e-6]
  warmup_steps: 
    values: [500, 1000]
  label_smoothing:
    values: [0,1e-1]

